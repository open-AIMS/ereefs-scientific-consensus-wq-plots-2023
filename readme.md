# eReefs BGC Seasonal plots for Scientific Consensus 2023
This repository contains the Python scripts that were used to generate plots of water quality variables from the eReefs BioGeoChemical model. These plots show annual averages (over 9 years) and seasonal (dry and wet) averages over 8 years. These plots use the eReefs [GBR4_H2p0_B3p1_Cq3b_Dhnd baseline scenario model data](https://thredds.ereefs.aims.gov.au/thredds/catalog/ereefs/GBR4_H2p0_B3p1_Cq3b_Dhnd.html) as regridded and aggregated into monthly data by the [AIMS eReefs THREDDs service](https://thredds.ereefs.aims.gov.au/thredds/catalog/catalog.html).

The plots are available in the [./export/single-plots](./export/single-plots) folder.

The following are instructions for reproducing these plots.

# License

This code is made available under an MIT license

# Setting up the environment
Create a Python Virtual Environment. I would recommend using Anaconda on Windows.

Certainly! Here's a step-by-step guide to set up a virtual environment in Anaconda on Windows and install the specified libraries:

1. **Install Anaconda (If you haven't already)**:
   - Download the Anaconda installer for Windows from [here](https://www.anaconda.com/products/distribution#download-section).
   - Follow the on-screen prompts to install Anaconda.
   - After installation, ensure that the Anaconda binaries are in your system's PATH or use the Anaconda Prompt for all the commands below.

2. **Open Anaconda Prompt**:
   - Search for "Anaconda Prompt" in your Windows search bar and open it. This command prompt has all the necessary configurations set for Anaconda.

3. **Create a new virtual environment**:
   - Use the following command to create a new virtual environment. Here, I'll name it `ereefs_maps`, but you can give it any name you prefer.
     ```
     conda create --name ereefs_maps python=3.10
     ```
   - You can replace `3.10` with your preferred Python version, but make sure the libraries you want to install are compatible with that version.

4. **Activate the virtual environment**:
   - Once the environment is created, activate it using the following command:
     ```
     conda activate ereefs_maps
     ```

5. **Install Libraries from the `requirements.txt` File**:

   Navigate to the directory where your `requirements.txt` is located (using the `cd` command). Then, use the following command to install the packages:
   ```bash
   pip install -r requirements.txt
   ```

   This will install all the libraries specified in the `requirements.txt` file into your `ereefs_maps` environment.

6. **Verify the installations**:
   - You can check that the libraries have been installed correctly by activating the environment and then launching Python:
     ```bash
     python
     ```
   - And then, for each library in the requirements try and import them:
     ```python
     import xarray
     import geopandas
     import matplotlib
     import cartopy
     ...
     ```
   - If no errors pop up after these import statements, it means the libraries are correctly installed.

6. **Run the scripts 01-...05**:
   Run each of the scripts in turn.
   
7. **Deactivate the environment when done**:
   - When you're done working in the `ereefs_maps` environment, deactivate it with:
     ```bash
     conda deactivate
     ```

That's it! You now have a virtual environment set up in Anaconda on Windows.

# Overview of scripts
To reproduce the plots all that is required is to run the scripts in sequence.

## 01-download-base-map-data.py
This script downloads the shapefiles needed to make the basemap in the plots. The data can be manually downloaded in a browser from: https://nextcloud.eatlas.org.au/s/RGwTFcLtmPApEcQ/download and extracted into `src-data/eReefs-BGC`.

## 02-get-monthly-ereefs-BGC-data.py
This script downloads the eReefs BGC data from the AIMS THREDDS data service using OpenDAP. It saves the data as a local NetCDF file for later processing.

## 03-calculate-all-time-aggregate.py
This script creates an annual aggregate for all the BGC variables of interest. This 
date range is limited so that only whole years are included.

## 04-calculate-seasonal-aggregates.py
This script generates season aggregates of the eReefs NetCDF BGC data downloaded in `02-get-monthly-ereefs-BGC-data.py`. This splits the time series into wet season months (11, 12, 1, 2, 3, 4) and dry season months (5, 6, 7, 8, 9, 10) prior to aggregation. The start of the time series is limited to ensure that only whole seasons are included in the average to remove bias from having only a partial season.

## 05-plot-BGC-1.py
This script generates all the plots. This script generates map plots of various variables from the BGC model annual and seasonal aggregations generated by `03-calculate-all-time-aggregate.py` and `04-calculate-seasonal-aggregates.py`. This outputs its figure as PNG files into `exports`. These have one variable, with one temporal aggregation per plot. The eReefs data is clipped to the GBR region.


# Script development notes and the use of assisted coding with GPT-4:
A lot of assistance for the creation of these scripts was provided by GPT-4 using the Code interpreter and the normal GPT-4 chat.

The development of the download and aggregation scripts used GPT-4 to create a basis for the code. This usually involved describing the initial goal of the script then refining the description over multiple interactions. Once most of the key features had been captured, the script was carefully reviewed for its validity and any tweaking or refining was done manually.

For the plotting script, the GPT-4 code interpreter was used. This allowed the actual data to be uploaded and for the code rendered by GPT-4 to be executed directly. This allowed GPT-4 to integrate the data files with code, allowing it to discover metadata and context information from the data files directly. This minimized the amount of description that was needed to trigger it to build the code. Generating the code for the plot was a significant challenge for GPT-4 with it typically generating about 80% of the requirements. I tried to be highly specific with the prompting and refined the prompt through multiple attempts. In some cases, GPT-4 would try to use libraries that it didn't have access to in its sandbox, so eventually, I added hints as to what libraries to use. The code interpreter didn't have the libraries to enable the clipping of the eReefs data to the GBR, and so I dropped this requirement from the prompt. Once there was a basic framework for the code, I shifted to executing the code locally and refining and adding parts to it using just the GPT-4 chat. In this case, I would prompt it with the existing code and indicate the feature or modification that I wished to change (such as clipping of the data to the GBR boundary). This process was repeated until each of the parts of the plots had been demonstrated. The font sizes, colors, positioning, layout, text, etc. were then all manually adjusted to produce a better plot. Finally, the code was refactored to enable the generation of multiple plots. This was done by converting the plot code into a function, setting up the key information for the plots as a configuration data structure so that the details of multiple variable plots could be made with no duplicate code.

I have recorded a summary of the key prompts that summarize the information that was requested from GPT-4. In most cases, this is a combination of information from multiple prompts to create a prompt that is likely a more complete description of the script. I am not sure that this information is useful.

## Installation instruction prompt
I want to setup a virtual environment in anaconda on windows with the following libraries installed: xarray geopandas matplotlib cartopy netCDF4. Can you generate a set of instructions to do this. How would us do this with a requirements.txt document?

## 01-download-base-map-data.py prompt

I want a Python script that will download and unzip a file from a specified URL. Can this be done with no additional libraries, just the ones already in Python 3.10. Can it also provide some feedback during the download and specify a user agent in the request.

## 02-get-monthly-ereefs-BGC-data.py 
I want to use OpenDAP to download a time series of a particular variable at a particular depth. The opendap service URL is https://thredds.ereefs.aims.gov.au/thredds/dodsC/GBR4_H2p0_B3p1_Cq3b_Dhnd/monthly.nc and the variable is DIN: Array of 32 bit Reals [time = 0..100][k = 0..16][latitude = 0..722][longitude = 0..490]. I want to download and save the variables, TN, TP, DIN, DIP, Chl_a_sum, NO3, NH4, DOR_N, DOR_P, PhyL_N, PhyL_NR, PhyS_N, PhyS_NR, Tricho_N, Tricho_NR for a specific depth (k) as a NetCDF file locally. I want it to provide some feedback during the downloading, by downloading one variable at a time and saving to NetCDF as the extraction takes 30 min. Is it possible to print a progress update each time a variable is calculated.



## 03-calculate-all-time-aggregate.py prompt and 04-calculate-seasonal-aggregates.py
I have NetCDF data ('src-data/eReefs-BGC/GBR4_H2p0_B3p1_Cq3b_Dhnd_WQ_monthly_3.0m.nc') with the following variables ('TN', 'TP', 'DIN', 'DIP', 'Chl_a_sum', 'NO3', 'NH4', 'DOR_N', 'DOR_P',  'PhyL_N', 'PhyL_NR', 'PhyS_N', 'PhyS_NR', 'Tricho_N', 'Tricho_NR'). Each variable is a 2D raster. The time series is monthly data from late 2010 through to 2019, with 101 time samples. I want to calculate an aggregate average over the time series for each variable and save the result as a new NetCDF file 'derived/eReefs-BGC/GBR4_H2p0_B3p1_Cq3b_Dhnd_WQ_all_3.0m.nc'.

Now I want to calculate averages for each season (wet and dry). The wet season corresponds to months November through to April and the dry season from May through to October. i.e. we want to take the average over all years for months  11, 12, 1, 2, 3, 4 as the wet season average and months 5, 6, 7, 8, 9, 10 as the dry season average.  The data in the file is in 101 month averages. 

## 05-plot-BGC-1.py prompt
The uploaded data includes spatial data for creating a base map of Queensland and its river basins (GBR_AIMS_eReefs-basemap_Land-and-Basins.shp), rivers (GBR_AIMS_eReefs-basemap_GA-topo5m-drainage.shp), reefs (GBR_AIMS_eReefs-basemap_Reefs.shp) and cities (GBR_AIMS_eReefs-basemap_Cities_2023.csv). There is also a NetCDF file containing aggregate (2011-2019) water quality raster data from the eReefs BGC model (GBR4_H2p0_B3p1_Cq3b_Dhnd_WQ_all_3.0m.nc). 
Main map:
The background of the main map should be very pale blue to represent the ocean. I want to create a main map that consists of a basemap with the following layering starting at the bottom:
1. eReef BGC DIN: The colour map for DIN should be logarithmic scale with values from 0.1 to 12.8. It should use a colourmap based on the following colours: #380060, #40009a, #2c30ee, #3a6ef1, #2fb0fb, #3ed6d6, #75eedc, #b1ffdb, #deffda, #ffff75, #ffef71, #ffc23d, #ff8700, #ff4400, #b00026, #5c0035.
2. Land and basins: The Land-and-Basins layer should be rendered with pale shades of grey, with styling based on the BASIN_ALT attribute. 'country','island','state' should all be a very pale grey. 'dbasin_0','dbasin_1','dbasin_2' are river basins attributed so each neighbouring basin don't have the same attribute. They should be styled with slightly different shades of grey. Still pale though.
3. Rivers: Rivers should be rendered over the top of the Land-and-Basins, using a medium dark muted blue colour.
4. Cities with an 'scs_scale' of 1 should be drawn on the map with a black dot. The city labels  should be drawn to the left of the marker. The labels be drawn with a white halo about the city labels to make the text stand out from the background. Use the 'latitude' and 'longitude' attributes for the spatial position of the cities.
5. Reefs: These should be rendered using transparent (80%) black.
The main map should have an extent of West: 142 deg, East: 154.2 deg, South: -26.7 deg, North: -10.0 deg.
Overview map:
A secondary overview map should be added as an overlay to the lower quarter of the map. It should fit inside the bottom corner of the main map. i.e. include code to allow the overview map to be positioned. This map should be no more than 25% of the width of the main map. This should consist of the GBR_AIMS_eReefs-basemap_NE-countries-10m data rendered in pale grey. A bounding box corresponding to the extent of the main map should be drawn as a box on the overview map.
General information:
Use xarray to load the NetCDF, geopandas for reading shapefiles and matplotlib for plotting. The data is in a zip file.



